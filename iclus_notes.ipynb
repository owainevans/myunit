{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http://ipython.org/ipython-doc/dev/parallel/parallel_details.html\n",
      "What is sendable?\n",
      "\n",
      "If IPython doesn\u2019t know what to do with an object, it will pickle it. There is a short list of objects that are not pickled: buffers, str/bytes objects, and numpy arrays. These are handled specially by IPython in order to prevent the copying of data. Sending bytes or numpy arrays will result in exactly zero in-memory copies of your data (unless the data is very small).\n",
      "\n",
      "If you have an object that provides a Python buffer interface, then you can always send that buffer without copying - and reconstruct the object on the other side in your own code. It is possible that the object reconstruction will become extensible, so you can add your own non-copying types, but this does not yet exist.\n",
      "Closures\n",
      "\n",
      "Just about anything in Python is pickleable. The one notable exception is objects (generally functions) with closures. Closures can be a complicated topic, but the basic principal is that functions that refer to variables in their parent scope have closures.\n",
      "\n",
      "An example of a function that uses a closure:\n",
      "\n",
      "def f(a):\n",
      "    def inner():\n",
      "        # inner will have a closure\n",
      "        return a\n",
      "    return inner\n",
      "\n",
      "f1 = f(1)\n",
      "f2 = f(2)\n",
      "f1() # returns 1\n",
      "f2() # returns 2\n",
      "\n",
      "f1 and f2 will have closures referring to the scope in which inner was defined, because they use the variable \u2018a\u2019. As a result, you would not be able to send f1 or f2 with IPython. Note that you would be able to send f. This is only true for interactively defined functions (as are often used in decorators), and only when there are variables used inside the inner function, that are defined in the outer function. If the names are not in the outer function, then there will not be a closure, and the generated function will look in globals() for the name:\n",
      "\n",
      "def g(b):\n",
      "    # note that `b` is not referenced in inner's scope\n",
      "    def inner():\n",
      "        # this inner will *not* have a closure\n",
      "        return a\n",
      "    return inner\n",
      "g1 = g(1)\n",
      "g2 = g(2)\n",
      "g1() # raises NameError on 'a'\n",
      "a=5\n",
      "g2() # returns 5\n",
      "\n",
      "g1 and g2 will be sendable with IPython, and will treat the engine\u2019s namespace as globals(). The pull() method is implemented based on this principle. If we did not provide pull, you could implement it yourself with apply, by simply returning objects out of the global namespace:\n",
      "\n",
      "In [10]: view.apply(lambda : a)\n",
      "\n",
      "# is equivalent to\n",
      "In [11]: view.pull('a')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Namespace module issues:\n",
      "http://stackoverflow.com/questions/10857250/python-name-space-issues-with-ipython-parallel/10859394#10859394\n",
      "\n",
      "Quick answer: decorate your function with @interactive from IPython.parallel.util[1] if you want it to have access to the engine's global namespace:\n",
      "\n",
      "from IPython.parallel.util import interactive\n",
      "f = interactive(lambda x: a+b+x)\n",
      "ack = dview.apply(f, x)\n",
      "\n",
      "The actual explanation:\n",
      "\n",
      "the IPython user namespace is essentially the module __main__. This is where code is run when you do execute('a = 5').\n",
      "\n",
      "If you define a function interactively, its module is also __main__:\n",
      "\n",
      "lam = lambda x: a+b+x\n",
      "lam.__module__\n",
      "'__main__'\n",
      "\n",
      "When the Engine unserializes a function, it does so in the appropriate global namespace for the function's module, so functions defined in __main__ in your client are also defined in __main__ on the Engine, and thus have access to a.\n",
      "\n",
      "Once you put it in a file and import it, then the functions are no longer attached to __main__, but the module dop:\n",
      "\n",
      "from dop import dop\n",
      "dop.__module__\n",
      "'dop'\n",
      "\n",
      "All functions conventionally defined in that module (lambdas included) will have this value, so when they are unpacked on the Engine their global namespace will be that of the dop module, not __main__, so your 'a' is not accessible.\n",
      "\n",
      "For this reason, IPython provides a simple @interactive decorator that results in any function being unpacked as if it were defined in __main__, regardless of where the function is actually defined.\n",
      "\n",
      "For an example of the difference, take this dop.py:\n",
      "\n",
      "from IPython.parallel import Client\n",
      "from IPython.parallel.util import interactive\n",
      "\n",
      "a = 1\n",
      "\n",
      "def dop(x):\n",
      "    rc = Client()\n",
      "    dview = rc[:]\n",
      "    dview['a'] = 5\n",
      "    f = lambda x: a+x\n",
      "    return dview.apply_sync(f, x)\n",
      "\n",
      "def idop(x):\n",
      "    rc = Client()\n",
      "    dview = rc[:]\n",
      "    dview['a'] = 5\n",
      "    f = interactive(lambda x: a+x)\n",
      "    return dview.apply_sync(f, x)\n",
      "\n",
      "Now, dop will use 'a' from the dop module, and idop will use 'a' from your engine namespaces. The only difference between the two is that the function passed to apply is wrapped in @interactive:\n",
      "\n",
      "from dop import dop, idop\n",
      "print dop(5)  # 6\n",
      "print idop(5) # 10\n",
      "\n",
      "[1]: In IPython >= 0.13 (upcoming release), @interactive is also available as from IPython.parallel import interactive, where it always should have been.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Error message trying to push a venture ripl to the engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ck (most recent call last)\n",
      "<ipython-input-159-32f9c09f55b7> in <module>()\n",
      "----> 1 v.dview.push({'vv':vv})\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/view.pyc in push(self, ns, targets, block, track)\n",
      "    700         if not isinstance(ns, dict):\n",
      "    701             raise TypeError(\"Must be a dict, not %s\"%type(ns))\n",
      "--> 702         return self._really_apply(util._push, kwargs=ns, block=block, track=track, targets=targets)\n",
      "    703 \n",
      "    704     def get(self, key_s):\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/view.pyc in _really_apply(self, f, args, kwargs, targets, block, track)\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/view.pyc in sync_results(f, self, *args, **kwargs)\n",
      "     61     self._in_sync_results = True\n",
      "     62     try:\n",
      "---> 63         ret = f(self, *args, **kwargs)\n",
      "     64     finally:\n",
      "     65         self._in_sync_results = False\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/view.pyc in _really_apply(self, f, args, kwargs, targets, block, track)\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/view.pyc in save_ids(f, self, *args, **kwargs)\n",
      "     46     n_previous = len(self.client.history)\n",
      "     47     try:\n",
      "---> 48         ret = f(self, *args, **kwargs)\n",
      "     49     finally:\n",
      "     50         nmsgs = len(self.client.history) - n_previous\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/view.pyc in _really_apply(self, f, args, kwargs, targets, block, track)\n",
      "    556         for ident in _idents:\n",
      "    557             msg = self.client.send_apply_request(self._socket, f, args, kwargs, track=track,\n",
      "--> 558                                     ident=ident)\n",
      "    559             if track:\n",
      "    560                 trackers.append(msg['tracker'])\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/client.pyc in send_apply_request(self, socket, f, args, kwargs, metadata, track, ident)\n",
      "   1250         bufs = serialize.pack_apply_message(f, args, kwargs,\n",
      "   1251             buffer_threshold=self.session.buffer_threshold,\n",
      "-> 1252             item_threshold=self.session.item_threshold,\n",
      "   1253         )\n",
      "   1254 \n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/zmq/serialize.pyc in pack_apply_message(f, args, kwargs, buffer_threshold, item_threshold)\n",
      "    159 \n",
      "    160     kw_keys = sorted(kwargs.keys())\n",
      "--> 161     kwarg_bufs = flatten(serialize_object(kwargs[key], buffer_threshold, item_threshold) for key in kw_keys)\n",
      "    162 \n",
      "    163     info = dict(nargs=len(args), narg_bufs=len(arg_bufs), kw_keys=kw_keys)\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/utils/data.pyc in flatten(seq)\n",
      "     26     \"\"\"Flatten a list of lists (NOT recursive, only works for 2d lists).\"\"\"\n",
      "     27 \n",
      "---> 28     return [x for subseq in seq for x in subseq]\n",
      "     29 \n",
      "     30 \n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/zmq/serialize.pyc in <genexpr>((key,))\n",
      "    159 \n",
      "    160     kw_keys = sorted(kwargs.keys())\n",
      "--> 161     kwarg_bufs = flatten(serialize_object(kwargs[key], buffer_threshold, item_threshold) for key in kw_keys)\n",
      "    162 \n",
      "    163     info = dict(nargs=len(args), narg_bufs=len(arg_bufs), kw_keys=kw_keys)\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/zmq/serialize.pyc in serialize_object(obj, buffer_threshold, item_threshold)\n",
      "    100         buffers.extend(_extract_buffers(cobj, buffer_threshold))\n",
      "    101 \n",
      "--> 102     buffers.insert(0, pickle.dumps(cobj,-1))\n",
      "    103     return buffers\n",
      "    104 \n",
      "\n",
      "RuntimeError: Pickling of \"venture.cxx.libtrace.Trace\" instances is not enabled (http://www.boost.org/libs/python/doc/v2/pickle.html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "For SO Question 14184621\n",
      "\n",
      "Connect to the cluster\n",
      "In [1]:\n",
      "\n",
      "from IPython.parallel import Client\n",
      "rc = Client()\n",
      "lview = rc.load_balanced_view()\n",
      "dv = rc[:]\n",
      "\n",
      "Define a magic that runs a cell locally and remotely\n",
      "In [2]:\n",
      "\n",
      "def pxlocal(line, cell):\n",
      "    ip = get_ipython()\n",
      "    ip.run_cell_magic(\"px\", line, cell)\n",
      "    ip.run_cell(cell)\n",
      "ip.register_magic_function(pxlocal, \"cell\")    \n",
      "\n",
      "Use the magic to define a class interactively everywhere (including local)\n",
      "In [3]:\n",
      "\n",
      "%%pxlocal\n",
      "class MyClass(object):\n",
      "    def __init__(self, parameter):\n",
      "        self.parameter = parameter\n",
      "\n",
      "    def update_something(self, some_data):\n",
      "       # do something smart here with some_data & internal state\n",
      "        self.parameter = some_data\n",
      "    \n",
      "    def compute_something(self, other_data):\n",
      "        # do something smart here with other data & internal state\n",
      "        return self.parameter * other_data\n",
      "\n",
      "Run some tasks\n",
      "In [4]:\n",
      "\n",
      "def process(obj, some_data, other_data):\n",
      "    obj.update_something(some_data)\n",
      "    return obj.compute_something(other_data)\n",
      "\n",
      "tasks = []\n",
      "some_instances = [MyClass(i) for i in range(5)]\n",
      "data_source_1 = range(1,4)\n",
      "data_source_2 = range(4,1,-1)\n",
      "for obj in some_instances:\n",
      "   for some_data in data_source_1:\n",
      "        for other_data in data_source_2:\n",
      "            ar = lview.apply_async(process, obj, some_data, other_data)\n",
      "            tasks.append(ar)\n",
      "\n",
      "# wait for computation to end\n",
      "results = [ar.get() for ar in tasks] \n",
      "\n",
      "In [5]:\n",
      "\n",
      "results[:18]\n",
      "\n",
      "Out[5]:\n",
      "\n",
      "[4, 3, 2, 8, 6, 4, 12, 9, 6, 4, 3, 2, 8, 6, 4, 12, 9, 6]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## nNOTES VIKASH CONVERSATION SPECCING OUT PARALLEL PROJECT\n",
      "#blocking is optional pass through (default is async), but wait() method will block on last thing\n",
      "\n",
      "# get access to master\n",
      "\n",
      "# write nose testing: capture spec for new methods that aren't in methods\n",
      "\n",
      "# test parallel machinery: compare to single ripl. fix seeds\n",
      "\n",
      "# support discrete data, make sure tests cover discrete\n",
      "\n",
      "# make sure 'procedure' data is handeled, throw an exception (Test should show exception)\n",
      "\n",
      "# discrete/cts, discrete 'scatter, 2d heatmap.\n",
      "\n",
      "# multiripl magic\n",
      "\n",
      "# starcluster, venture installed, template\n",
      "\n",
      "# clear shouldn't destroy the seed (delegate new seed after clear)\n",
      "\n",
      "# continuous inference\n",
      "\n",
      "# map somethign across all ripls\n",
      "\n",
      "# for mripl, what's procesdure i used to display state (one magic)\n",
      "# separate magic for running for the pgoram\n",
      "\n",
      "# 1. cell for no_ripls. (doesnt need magic) 2. one magic for update display. \n",
      "\n",
      "# display() :: ripl,fig  ->    string, fig \n",
      "# mr.set_display(display)\n",
      "# mr.display(plot = true, model = random (vs. all) )\n",
      "# calls display attribute, displays results and collects them)\n",
      "\n",
      "# CRP: discrete values, plots.\n",
      "\n",
      "# Demos: IPython.parallle, skip bokeh, readme, intro to start walkers. \n",
      "\n",
      "# Walk through, applying to crp mixture. \n",
      "\n",
      "# ADD this spec to Asana. (Alexey a follower, + vikash)\n",
      "\n",
      "# baxter.\n",
      "\n",
      "# #Python Freenode:#Python (channel), minrk or min_rk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More notes:\n",
      "1. Copying could be done by pushing once we go Venture-lite. At the moment, cxx objects don't allow pickling but there's no reason they shouldn't. So should keep in mind that this is possible.\n",
      "\n",
      "2. If we can copy, we can have multiripls created from an existing ripl. Push across and change the seed on each of the spawned ripls. (Should we think about running multiple mriples per ipython insetance? doesn't seem it would be so problematic, with python balancing the ripls across the engines. Would allow exploration of different ripls in one seamless session. Could do comparisons of run time and inference quality in one notebook session. \n",
      "\n",
      "Simple model we considered was having a single multiripl in global of ipython client, much as we had ipy_ripl as part of the magic. We load the mripl class on startup. We open an %mripl magic."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(run ipcluster ... fire up engines)   # is there a good way of doing this within notebook?\n",
      "\n",
      "> ipcluster -n 10\n",
      "> IPython -multiripl\n",
      "\n",
      "# On startup, IPython loads MultiRipl class and associated magics\n",
      "\n",
      "\n",
      "#### WORKING WITH SINGLE MULTIRIPL\n",
      "\n",
      "## Create a MultiRipl object\n",
      "mripl1 = MultiRipl(no_ripls=5)\n",
      "Out:[ (pid=3233, ripls=(0,1)), (pid=3234, ripls=(2,3) ) .. ]  # outputs [ (pid of engine, ripls running on engine) ... ]\n",
      "\n",
      "## Interact with this multiripl, using python syntax\n",
      "mripl1.assume('x','(beta 1 1)')\n",
      "mripl1.add_ripls(no_ripls=10)\n",
      "mripl1.infer(10); mripl1.snapshot(1,plot=True)\n",
      "\n",
      "        \n",
      "## Interact using cell/line magic, specifying name of mripl in the line\n",
      "# (multiripl has a shadow execute_program method)\n",
      "%%mr_vmagic  name=mripl1   \n",
      "[assume x 1]\n",
      "[predict (+ x 1)]\n",
      "# Note: I think we could have an interactively generated cell_magic for each created mripl, but that \n",
      "# doesn't seem necessary.\n",
      " \n",
      "\n",
      "## Map arbitrary procedure across all the ripls using cell magic [NOT FULLY IMPLEMENTED]\n",
      "%%mr_map   name=mripl1  proc_name=crp_plot  plot=True\n",
      "\n",
      "import matplotlib.pylab as plt; import numpy as np\n",
      "\n",
      "from my_crp_utils import crp_helper\n",
      "\n",
      "def crp_helper_func(x): return helpful_out\n",
      "\n",
      "def crp_plot(ripl):\n",
      "    crp_helper_func(ripl)\n",
      "    N = ripl.report(label='N')\n",
      "    X_values = [ripl.report(label='x_'+str(i) ) for i in range(N) ]\n",
      "    Z_values = [ripl.report(label='z_'+str(i) ) for i in range(N) ]\n",
      "    fig, ax = plt.subplots()\n",
      "    ax.scatter(X_values[:,0],X_values[:,1], Z_values)\n",
      "    return X_values,Z_values,fig\n",
      "\n",
      "Out: figures are plotted inline, either via subplots or slideshow in Bokeh\n",
      "\n",
      "# Note: the code is execute on all ripls via %%px parallel cell magic\n",
      "# you can define variables and do imports. You can't push variables\n",
      "# across using this magic. The function specified in the line (proc_name)\n",
      "# will be mapped across all ripls. It has to take a ripl as its sole\n",
      "# argument. The function can use variables/modules defined in the global environment of \n",
      "# the engines.\n",
      "\n",
      "\n",
      "## Re-use the same mapped procedure after more interaction\n",
      "\n",
      "mripl1.add_ripls(10)\n",
      "mripl1.infer(1000)\n",
      "\n",
      "%%mr_map   name=mripl1   proc_name=crp_plot  plot=True\n",
      "\n",
      "# called with no cell, mr_map will map the previously defined procedure\n",
      "# across all current ripls. \n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Creating multiple multiripls:</b>\n",
      "\n",
      "I could change the current MultiRipl class to allow a single IPython session to control more than one MultiRipl object. \n",
      "\n",
      "The current class constructor creates a list of ripls for each engine as follows:\n",
      "\n",
      "```\n",
      "dview.execute('ripls = []') \n",
      "```\n",
      "\n",
      "and then populates it by mapping this function across the engines:\n",
      "\n",
      "```\n",
      "def mk_ripl(seed): ripls.append( make_church_prime_ripl() )\n",
      "\n",
      "dview.map( mk_ripl, seeds )\n",
      "```\n",
      "\n",
      "The directives are applied to the ripls using parallel 'apply' and functions like this:\n",
      "```\n",
      " def predict(self,exp):\n",
      "        def f(exp): return [ripl.predict(exp) for ripl in ripls]\n",
      "        return self.dview.apply(f,exp)\n",
      "```\n",
      "Instead, we could assign a unique number (mripl_id) to each MultiRipl in the global environment and use that number to send directives to the right set of ripls. \n",
      "\n",
      "So the constructor would be:\n",
      "\n",
      "```\n",
      "dview.execute('ripls[%i] = []' % mriple_id)\n",
      "\n",
      "def mk_ripl(seed,mripl_id): ripls[mripl_id].append( make_church_prime_ripl() )\n",
      "dview.map( mk_ripl, zip(seeds,[mripl_id]*len(seeds)) )</code>\n",
      "```\n",
      "\n",
      "The directives would be:\n",
      "```\n",
      " def predict(self,exp):\n",
      "        def f(exp,mripl_id): return [ripl.predict(exp) for ripl in ripls[mripl_id] ]\n",
      "        return self.dview.apply(f,exp,mripl_id)\n",
      "```\n",
      "        \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### PLAN\n",
      "# 1. make display work and plot with discrete and cts inputs. \n",
      "#   so the crp example (maybe with ellipsoids). \n",
      "#     -- should add snapshot, as display will depend on it.\n",
      "# 2. change everything to sync (will save time quickly).\n",
      "# 3. have the local ripl be optional\n",
      "# 4. nosify the tests\n",
      "# 5. add all directives\n",
      "# 6. record no_total_transitions (with snapshot)\n",
      "\n",
      "\n",
      "\n",
      "# seems we can use magic commands in a %px\n",
      "# and so the engines are running ipython\n",
      "# --though they don't get the ipy_ripl (why not?)\n",
      "\n",
      "# question of what happens when you push a function to them\n",
      "# functions can't be mutated, so a pointer to a function\n",
      "# should be the same as copying the function, apart from \n",
      "# the issue of the enclosing env. so: the function you\n",
      "# push is like a copy, it doesn't maintain the closure\n",
      "# (makes sense, coz we can't send across functions with closures)\n",
      "\n",
      "s='local';\n",
      "f=lambda:s; \n",
      "dv.push({'f':f}); \n",
      "%px f() = error (no s var)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "Ripl instance has no attribute 'exe'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-00f3d6f9f355>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: Ripl instance has no attribute 'exe'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}